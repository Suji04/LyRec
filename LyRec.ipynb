{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3X-NTEVAcyLr"
   },
   "outputs": [],
   "source": [
    "root_dir = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Og0952Zkc8oF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from google.colab import userdata\n",
    "from huggingface_hub import login\n",
    "login(userdata.get(\"HF_TOKEN\"))\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LpaBFEWAnIuy"
   },
   "outputs": [],
   "source": [
    "songs_df = pd.read_csv(f\"{root_dir}/spotify_millsongdata.csv\")\n",
    "songs_df = songs_df.drop(columns=[\"link\"])\n",
    "songs_df[\"song_id\"] = songs_df.index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndfu6Gkudkb8"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TsYCozuPft3o"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "embedding_model = SentenceTransformer(\n",
    "    \"Alibaba-NLP/gte-Qwen2-1.5B-instruct\",\n",
    "    model_kwargs={\"torch_dtype\": torch.float16}\n",
    ")\n",
    "\n",
    "embedding_model.max_seq_length = 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73UWohAadMi1"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"google/gemma-2-2b-it\",\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device=\"cuda\",\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKKmTHakd3ug"
   },
   "source": [
    "# Pre-computing the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9yzFsTJzd1pt"
   },
   "outputs": [],
   "source": [
    "def batch_summarize(lyrics_list, batch_size):\n",
    "    prompts = [\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"You are an expert song summarizer. You will be given the full lyrics \"\n",
    "                    \"to a song. Your task is to write a concise, cohesive summary that \"\n",
    "                    \"captures the central emotion, overarching theme, key elements, and \"\n",
    "                    \"narrative arc of the song in 200 words.\\n\\n\"\n",
    "                    f\"{lyrics}\"\n",
    "                ),\n",
    "            }\n",
    "        ]\n",
    "        for lyrics in lyrics_list\n",
    "    ]\n",
    "\n",
    "    all_summaries = []\n",
    "\n",
    "    for i in tqdm(range(0, len(prompts), batch_size)):\n",
    "        batch_prompts = prompts[i : i + batch_size]\n",
    "\n",
    "        outputs = summarizer(\n",
    "            batch_prompts,\n",
    "            max_new_tokens=256,\n",
    "        )\n",
    "\n",
    "        for output in outputs:\n",
    "            generated_text = output[0][\"generated_text\"]\n",
    "            assistant_message = generated_text[-1][\"content\"]\n",
    "            summary = assistant_message.strip()\n",
    "            all_summaries.append(summary)\n",
    "\n",
    "    return all_summaries\n",
    "\n",
    "lyrics_list = songs_df[\"text\"].values\n",
    "summaries = batch_summarize(lyrics_list, batch_size=16)\n",
    "songs_df[\"summary\"] = summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48GYpDitsrLL"
   },
   "outputs": [],
   "source": [
    "song_lyrics = songs_df[\"text\"].values\n",
    "song_summary = songs_df[\"summary\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-wYGkvVks6wA"
   },
   "outputs": [],
   "source": [
    "lyrics_embeddings = embedding_model.encode(\n",
    "    song_lyrics,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "np.save(f\"{root_dir}/60k_song_lyrics_embeddings.npy\", lyrics_embeddings)\n",
    "\n",
    "summary_embeddings = embedding_model.encode(\n",
    "    song_summary,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "np.save(f\"{root_dir}/60k_song_summary_embeddings.npy\", summary_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBo-V2qM-jH6"
   },
   "source": [
    "# Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVPYcNGj-u1T"
   },
   "outputs": [],
   "source": [
    "lyrics_embeddings = np.load(f\"{root_dir}/60k_song_lyrics_embeddings.npy\")\n",
    "lyrics_index = faiss.IndexFlatIP(lyrics_embeddings.shape[1])\n",
    "lyrics_index.add(lyrics_embeddings.astype(np.float32))\n",
    "\n",
    "summary_embeddings = np.load(f\"{root_dir}/60k_song_summary_embeddings.npy\")\n",
    "summary_index = faiss.IndexFlatIP(summary_embeddings.shape[1])\n",
    "summary_index.add(summary_embeddings.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "un_0XcExAAW_"
   },
   "source": [
    "# LyRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5gvunhLXACg8"
   },
   "outputs": [],
   "source": [
    "class LyRec:\n",
    "    def __init__(self, songs_df, lyrics_index, summary_index, embedding_model):\n",
    "        self.songs_df = songs_df\n",
    "        self.lyrics_index = lyrics_index\n",
    "        self.summary_index = summary_index\n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "    def get_records_from_id(self, song_ids):\n",
    "        songs = []\n",
    "        for _id in song_ids:\n",
    "            songs.extend(self.songs_df[self.songs_df[\"song_id\"]==_id+1].to_dict(orient='records'))\n",
    "        return songs\n",
    "\n",
    "    def get_songs_with_similar_lyrics(self, query_lyrics, k=10):\n",
    "        query_embedding = self.embedding_model.encode(\n",
    "            f\"Instruct: Given the lyrics, retrieve relevant songs\\n Query: {query_lyrics}\"\n",
    "        ).reshape(1, -1).astype(np.float32)\n",
    "\n",
    "        scores, song_ids = self.lyrics_index.search(query_embedding, k)\n",
    "        return self.get_records_from_id(song_ids[0])\n",
    "\n",
    "    def get_songs_with_similar_description(self, query_description, k=10):\n",
    "        query_embedding = self.embedding_model.encode(\n",
    "            f\"Instruct: Given a description, retrieve relevant songs\\n Query: {query_description}\"\n",
    "        ).reshape(1, -1).astype(np.float32)\n",
    "\n",
    "        scores, song_ids = self.summary_index.search(query_embedding, k)\n",
    "        return self.get_records_from_id(song_ids[0])\n",
    "\n",
    "    def get_songs_with_similar_lyrics_and_description(self, query_lyrics, query_description, k=10):\n",
    "        query_lyrics_embedding = self.embedding_model.encode(\n",
    "            f\"Instruct: Given the lyrics, retrieve relevant songs\\n Query: {query_lyrics}\"\n",
    "        ).reshape(1, -1).astype(np.float32)\n",
    "\n",
    "        scores, song_ids = self.lyrics_index.search(query_lyrics_embedding, 500)\n",
    "        top_k_indices = song_ids[0]\n",
    "\n",
    "        summary_candidates = []\n",
    "        for idx in top_k_indices:\n",
    "            emb = self.summary_index.reconstruct(int(idx))\n",
    "            summary_candidates.append(emb)\n",
    "        summary_candidates = np.array(summary_candidates, dtype=np.float32)\n",
    "\n",
    "        temp_index = faiss.IndexFlatIP(summary_candidates.shape[1])\n",
    "        temp_index.add(summary_candidates)\n",
    "\n",
    "        query_description_embedding = self.embedding_model.encode(\n",
    "            f\"Instruct: Given a description, retrieve relevant songs\\n Query: {query_description}\"\n",
    "        ).reshape(1, -1).astype(np.float32)\n",
    "\n",
    "        scores, temp_ids = temp_index.search(query_description_embedding, k)\n",
    "        final_song_ids = [top_k_indices[i] for i in temp_ids[0]]\n",
    "\n",
    "        return self.get_records_from_id(final_song_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1sDhqr1RRfw"
   },
   "outputs": [],
   "source": [
    "recommender = LyRec(songs_df, lyrics_index, summary_index, embedding_model)\n",
    "recommender.get_songs_with_similar_lyrics_and_description(\"Lyrics of a song\", \n",
    "                                                          \"Describe the type of song you want to listen to\", \n",
    "                                                          5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Q2OpLhBbKo9X"
   ],
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
